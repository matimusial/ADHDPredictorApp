<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ADHDPredictorApp</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <img src="logo.png" alt="Logo" class="logo">
    <h1>ADHDPredictorApp</h1>
    <nav>
        <a href="#" class="tablink active" data-tab="overview">Overview</a>
        <a href="#" class="tablink" data-tab="admin">Admin Instructions</a>
        <a href="#" class="tablink" data-tab="specification">Specification</a>
        <a href="#" class="tablink" data-tab="click-the-red-dot">Click the Brain</a>
        <a href="#" class="tablink" data-tab="pong">Brain pong</a>
        <a href="#" class="tablink" data-tab="tic-tac-toe">Tic Tac Brain</a>
    </nav>

    <div id="tic-tac-toe" class="content">
    <h2>Tic Tac Brain</h2>
    <div id="ticTacToeBoard">
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
        <div class="cell" data-cell></div>
    </div>
    <p id="winningMessage" class="hidden">Winner: <span id="winner"></span></p>
    <button id="restartButton">Restart</button>
</div>

    <div id="overview" class="content active">
        <h2>Overview</h2>
        <p>This project aims to predict ADHD (Attention Deficit Hyperactivity Disorder) in children using Convolutional Neural Networks (CNN). It utilizes two main datasets: EEG brain wave data and MRI brain images. The project consists of two main components:</p>
        <ol>
            <li><strong>EEG Data Analysis</strong>: Using EEG data to predict the presence of ADHD in children with deep learning models.</li>
            <li><strong>MRI Data Augmentation and Analysis</strong>: Generating additional MRI brain images using Generative Adversarial Networks (GAN) and using CNN to predict ADHD from original images.</li>
        </ol>
        <h2>Datasets</h2>
        <h3>EEG Data</h3>
        <p>The EEG dataset is a collection of brain waves from children, both with and without ADHD. This data is crucial for training our model to identify patterns associated with ADHD.</p>
        <p><strong>Source</strong>: <a href="https://ieee-dataport.org/open-access/eeg-data-adhd-control-children">EEG Data for ADHD and Control Children</a></p>
        <h3>MRI Data</h3>
        <p>The MRI dataset provides brain images, which are used along with generated images to enhance the model's training and prediction capabilities.</p>
        <p><strong>Source</strong>: <a href="https://openneuro.org/datasets/ds002424/versions/1.2.0">OpenNeuro Dataset ds002424</a></p>
        <h2>Methodology</h2>
        <ol>
            <li><strong>EEG Data Processing and Model Training</strong>: EEG data is processed into a format suitable for CNN analysis. Then, a deep learning model is trained to identify ADHD features from EEG patterns.</li>
            <li><strong>MRI Image Generation and Processing</strong>: GANs are used to generate additional MRI images to increase the existing dataset. These images are then processed and used to train another CNN model to predict ADHD.</li>
        </ol>
        <h2>Objectives</h2>
        <ul>
            <li>Provide an accurate and reliable method for predicting ADHD using non-invasive EEG and MRI data.</li>
            <li>Increase the availability of high-quality MRI brain images through generative techniques, supporting the development of robust predictive models.</li>
        </ul>
        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="admin" class="content">
        <h2>Admin Instructions</h2>
        <p>To access the admin view, press the "Admin View" button on the left side of the program window (the one that appears when you start the program).</p>
        <ul>
            <li><strong>"GAN for MRI"</strong> - (Button) Window for training the GAN model to generate MRI images</li>
            <li><strong>"CNN for MRI"</strong> - (Button) Window for training the CNN model for MRI images</li>
            <li><strong>"CNN for EEG"</strong> - (Button) Window for training the CNN model for EEG waves</li>
            <li><strong>"Exit"</strong> - (Button) Closes the application</li>
            <li><strong>"Database Admin"</strong> - (Button) Connects to the database and displays its contents with the option to delete models (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"USER VIEW"</strong> - (Button) Returns to the main window</li>
        </ul>

        <h3>CNN for EEG</h3>
        <ul>
            <li><strong>"Choose folder with data"</strong> - (button) text type</li>
            <p>The folder with training data must have the following structure:</p>
            <pre>(chosen folder)
    |
    | ADHD
    |    |
    |    [files of the ADHD group .mat/.csv/.edf]
    |
    | CONTROL
    |    |
    |    [files of the control group .mat/.csv/.edf]</pre>
            <li><strong>"Epochs"</strong> - numeric type</li>
            <li><strong>"Batch size"</strong> - numeric type</li>
            <li><strong>"Learning rate"</strong> - floating-point type</li>
            <li><strong>"Description"</strong> - (text type) Description for the model saved in the database</li>
            <li><strong>"Start"</strong> - (button) Starts the model training process</li>
            <li><strong>"Stop"</strong> - (button) Stops the model training process at the last epoch</li>
            <li><strong>"Save model to db"</strong> - (button) When the model is ready, saves it to the database (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"Delete model"</strong> - (button) When the model is ready, deletes it without saving to the database</li>
        </ul>

        <h3>CNN for MRI</h3>
        <ul>
            <li><strong>"Epochs"</strong> - numeric type</li>
            <li><strong>"Batch size"</strong> - numeric type</li>
            <li><strong>"Learning rate"</strong> - floating-point type</li>
            <li><strong>"Description"</strong> - (text type) Description for the model saved in the database</li>
            <li><strong>"Start"</strong> - (button) Starts the model training process</li>
            <li><strong>"Stop"</strong> - (button) Stops the model training process at the last epoch</li>
            <li><strong>"Save model to db"</strong> - (button) When the model is ready, saves it to the database (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"Delete model"</strong> - (button) When the model is ready, deletes it without saving to the database</li>
        </ul>

        <h3>GAN for MRI</h3>
        <ul>
            <li><strong>"Epochs"</strong> - numeric type</li>
            <li><strong>"Batch size"</strong> - numeric type</li>
            <li><strong>"Learning rate"</strong> - floating-point type</li>
            <li><strong>"Control/ADHD"</strong> - radio button to select the type of training data</li>
            <li><strong>"Print plot int."</strong> - numeric type</li>
            <li><strong>"Disp interval"</strong> - numeric type</li>
            <li><strong>"Description"</strong> - (text type) Description for the model saved in the database</li>
            <li><strong>"Start"</strong> - (button) Starts the model training process</li>
            <li><strong>"Stop"</strong> - (button) Stops the model training process at the last epoch</li>
            <li><strong>"Save model to db"</strong> - (button) When the model is ready, saves it to the database (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"Delete model"</strong> - (button) When the model is ready, deletes it without saving to the database</li>
        </ul>

        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="specification" class="content">
        <h2>Specification</h2>
        <h3>Data Analysis for Training CNN with EEG Data</h3>
        <ol>
            <li><strong>Data Loading and Filtering:</strong> EEG data is processed with a Butterworth bandpass filter with a lower frequency of 4 Hz and an upper frequency of 30 Hz.</li>
            <li><strong>Data Clipping:</strong> After filtering, the data is clipped to the 99.8th percentile, removing the extreme 0.2% of data.</li>
            <li><strong>Data Normalization:</strong> Data is normalized to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is transformed into images of fixed size (frame size), labeled, shuffled, and fed into the neural network in the shape (number of images, number of channels, frame size, 1).</li>
        </ol>
        <h3>CNN Architecture for EEG Training</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(number of channels, frame size, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 16.</li>
                    <li>Kernel size: (10, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Feature extraction from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (8, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (4, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of even more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 64.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Data Analysis for Training CNN with MRI Data</h3>
        <ol>
            <li><strong>Data Loading:</strong> Data with image size 128x120.</li>
            <li><strong>Data Clipping:</strong> Clipping by 4 pixels top-bottom, checking if the image is square.</li>
            <li><strong>Data Normalization:</strong> Normalizing to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is labeled and fed into training as (number of images, 120, 120, 1).</li>
        </ol>
        <h3>Training CNN for MRI Data</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(120, 120, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of basic features from input data.</li>
                </ul>
            </li>
            <li><strong>First Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Second Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 128.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of even more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Third Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 128.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Prediction for CNN Models for EEG and MRI</h3>
        <p><strong>Data Processing:</strong></p>
        <ul>
            <li>Data processed the same way as before training.</li>
            <li>The model returns a binary probability for each frame.</li>
            <li>The mean of the frames is calculated:
                <ul>
                    <li>If the mean exceeds the threshold of 0.5, the result is ADHD, and the mean * 100% is displayed.</li>
                    <li>If the result is healthy, (1 - mean) * 100% is displayed.</li>
                </ul>
            </li>
        </ul>
        <h3>Building and Training GAN Model</h3>
        <ol>
            <li><strong>Building the Generative Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 1024 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 120 * 120 * 1, activation 'tanh', Reshape to shape (120,120,1).</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Building the Discriminator Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Input: Input shape (120, 120, 1).</li>
                            <li>Flatten.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 1, activation 'sigmoid'.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Training the GAN Model:</strong>
                <ul>
                    <li>Gradient Tape: Using two tf.GradientTape objects to record operations for calculating gradients for the generator and discriminator.</li>
                    <li>Generating images: Generating fake images using the generator.</li>
                    <li>Passing through the discriminator:
                        <ul>
                            <li>Passing real images through the discriminator.</li>
                            <li>Passing generated images through the discriminator.</li>
                        </ul>
                    </li>
                    <li>Calculating losses:
                        <ul>
                            <li>Loss for the generator: g_loss calculated as the error of classifying fake images as real.</li>
                        </ul>
                    </li>
                    <li>Calculating gradients:
                        <ul>
                            <li>Gradients for the discriminator.</li>
                            <li>Gradients for the generator.</li>
                        </ul>
                    </li>
                    <li>Updating weights:
                        <ul>
                            <li>Applying gradients to optimizers to update weights of the discriminator and generator.</li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ol>
        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="click-the-red-dot" class="content">
        <h2>Click the Brain</h2>
        <div id="gameArea">
            <img id="target" src="pilka.png" alt="Target">
        </div>
        <p>Result: <span id="score">0</span></p>
        <div id="averageTime">Average time: 0 ms</div>
    </div>

    <div id="pong" class="content">
        <h2>Brain pong</h2>
        <canvas id="pongCanvas"></canvas>
         <button id="startButton">Start</button>
    </div>

    <script src="script.js"></script>
    <script src="red_dot.js"></script>
    <script src="tic_tac.js"></script>
    <script src="ping_pong.js"></script>
</body>
</html>
