<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ADHDPredictorApp</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        p {
            margin: 10px 0;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        nav {
            margin-bottom: 20px;
        }
        nav a {
            margin-right: 15px;
            color: #3498db;
        }
        nav a.active {
            font-weight: bold;
            color: #2c3e50;
        }
        .content {
            display: none;
        }
        .content.active {
            display: block;
        }
        .logo {
            width: 50px;
            height: 50px;
        }

    </style>
</head>
<body>
    <img src="logo.png" alt="Logo" class="logo">
    <h1>ADHDPredictorApp</h1>
    <nav>
        <a href="#" class="tablink active" data-tab="overview">Overview</a>
        <a href="#" class="tablink" data-tab="admin">Admin Instructions</a>
        <a href="#" class="tablink" data-tab="specification">Specification</a>
    </nav>

    <div id="overview" class="content active">
        <h2>Overview</h2>
        <p>This project aims to predict ADHD (Attention Deficit Hyperactivity Disorder) in children using Convolutional Neural Networks (CNN). It utilizes two main datasets: EEG brain wave data and MRI brain images. The project consists of two main components:</p>
        <ol>
            <li><strong>EEG Data Analysis</strong>: Using EEG data to predict the presence of ADHD in children with deep learning models.</li>
            <li><strong>MRI Data Augmentation and Analysis</strong>: Generating additional MRI brain images using Generative Adversarial Networks (GAN) and using CNN to predict ADHD from these images.</li>
        </ol>
        <h2>Datasets</h2>
        <h3>EEG Data</h3>
        <p>The EEG dataset is a collection of brain waves from children, both with and without ADHD. This data is crucial for training our model to identify patterns associated with ADHD.</p>
        <p><strong>Source</strong>: <a href="https://ieee-dataport.org/open-access/eeg-data-adhd-control-children">EEG Data for ADHD and Control Children</a></p>
        <h3>MRI Data</h3>
        <p>The MRI dataset provides brain images, which are used along with generated images to enhance the model's training and prediction capabilities.</p>
        <p><strong>Source</strong>: <a href="https://openneuro.org/datasets/ds002424/versions/1.2.0">OpenNeuro Dataset ds002424</a></p>
        <h2>Methodology</h2>
        <ol>
            <li><strong>EEG Data Processing and Model Training</strong>: EEG data is processed into a format suitable for CNN analysis. Then, a deep learning model is trained to identify ADHD features from EEG patterns.</li>
            <li><strong>MRI Image Generation and Processing</strong>: GANs are used to generate additional MRI images to increase the existing dataset. These images are then processed and used to train another CNN model to predict ADHD.</li>
        </ol>
        <h2>Objectives</h2>
        <ul>
            <li>Provide an accurate and reliable method for predicting ADHD using non-invasive EEG and MRI data.</li>
            <li>Increase the availability of high-quality MRI brain images through generative techniques, supporting the development of robust predictive models.</li>
        </ul>
        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="admin" class="content">
        <h2>Admin Instructions</h2>
        <p>To access the admin view, press the "Admin View" button on the left side of the program window (the one after launching the program).</p>
        <ul>
            <li><strong>USER VIEW</strong> - Returns to the main window</li>
            <li><strong>GAN for MRI</strong> - Window for training the GAN model to generate MRI images</li>
            <li><strong>CNN for MRI</strong> - Window for training the CNN model for MRI images</li>
            <li><strong>CNN for EEG</strong> - Window for training the CNN model for EEG waves</li>
        </ul>
        <h3>=CNN for EEG=</h3>
        <p>- <strong>"Chose folder with data"</strong> - (button) text type<br>
        The training data folder must have the following structure:<br>
        (selected folder)<br>
        &nbsp;&nbsp;&nbsp;&nbsp;|<br>
        &nbsp;&nbsp;&nbsp;&nbsp;| ADHD<br>
        &nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;|<br>
        &nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;[files for the ADHD group .mat/.csv/.edf]<br>
        &nbsp;&nbsp;&nbsp;&nbsp;|<br>
        &nbsp;&nbsp;&nbsp;&nbsp;| CONTROL<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[files for the control group .mat/.csv/.edf]<br>
        </p>
        <p>- <strong>"Epochs"</strong> - numeric type, default 20</p>
        <p>- <strong>"Batch size"</strong> - numeric type, default 32</p>
        <p>- <strong>"Learning rate"</strong> - float type, default 0.001</p>
        <p>- <strong>"Electrodes"</strong> - numeric type, default 19</p>
        <p>- <strong>"Frame size"</strong> - numeric type, default 128</p>
        <p>- <strong>"Frequency"</strong> - numeric type, default 128</p>
        <p>- <strong>"Start"</strong> - (button) Starts the model training process</p>
        <p>- <strong>[PLOT]</strong> - (graph) Displays the Accuracy and Loss values after training starts in real-time</p>
        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="specification" class="content">
        <h2>Specification</h2>
        <h3>Data Analysis for Training CNN with EEG Data</h3>
        <ol>
            <li><strong>Data Loading and Filtering:</strong> EEG data is processed with a Butterworth bandpass filter with a lower frequency of 4 Hz and an upper frequency of 30 Hz.</li>
            <li><strong>Data Clipping:</strong> After filtering, the data is clipped to the 99.8th percentile, removing the extreme 0.2% of data.</li>
            <li><strong>Data Normalization:</strong> Data is normalized to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is transformed into images of fixed size (frame size), labeled, shuffled, and fed into the neural network in the shape (number of images, number of channels, frame size, 1).</li>
        </ol>
        <h3>CNN Architecture for EEG Training</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(number of channels, frame size, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 16.</li>
                    <li>Kernel size: (10, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Feature extraction from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (8, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (4, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of even more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 64.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Data Analysis for Training CNN with MRI Data</h3>
        <ol>
            <li><strong>Data Loading:</strong> Data with image size 128x120.</li>
            <li><strong>Data Clipping:</strong> Clipping by 4 pixels top-bottom, checking if the image is square.</li>
            <li><strong>Data Normalization:</strong> Normalizing to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is labeled and fed into training as (number of images, 120, 120, 1).</li>
        </ol>
        <h3>Training CNN for MRI Data</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(120, 120, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of basic features from input data.</li>
                </ul>
            </li>
            <li><strong>First Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Second Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 128.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of even more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Third Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 128.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Prediction for CNN Models for EEG and MRI</h3>
        <p><strong>Data Processing:</strong></p>
        <ul>
            <li>Data processed the same way as before training.</li>
            <li>The model returns a binary probability for each frame.</li>
            <li>The mean of the frames is calculated:
                <ul>
                    <li>If the mean exceeds the threshold of 0.5, the result is ADHD, and the mean * 100% is displayed.</li>
                    <li>If the result is healthy, (1 - mean) * 100% is displayed.</li>
                </ul>
            </li>
        </ul>
        <h3>Building and Training GAN Model</h3>
        <ol>
            <li><strong>Building the Generative Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 1024 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 120 * 120 * 1, activation 'tanh', Reshape to shape (120,120,1).</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Building the Discriminator Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Input: Input shape (120, 120, 1).</li>
                            <li>Flatten.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 1, activation 'sigmoid'.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Training the GAN Model:</strong>
                <ul>
                    <li>Gradient Tape: Using two tf.GradientTape objects to record operations for calculating gradients for the generator and discriminator.</li>
                    <li>Generating images: Generating fake images using the generator.</li>
                    <li>Passing through the discriminator:
                        <ul>
                            <li>Passing real images through the discriminator.</li>
                            <li>Passing generated images through the discriminator.</li>
                        </ul>
                    </li>
                    <li>Calculating losses:
                        <ul>
                            <li>Loss for the generator: g_loss calculated as the error of classifying fake images as real.</li>
                        </ul>
                    </li>
                    <li>Calculating gradients:
                        <ul>
                            <li>Gradients for the discriminator.</li>
                            <li>Gradients for the generator.</li>
                        </ul>
                    </li>
                    <li>Updating weights:
                        <ul>
                            <li>Applying gradients to optimizers to update weights of the discriminator and generator.</li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ol>
        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <script>
        document.querySelectorAll('.tablink').forEach(function(tablink) {
            tablink.addEventListener('click', function(e) {
                e.preventDefault();
                document.querySelectorAll('.tablink').forEach(function(link) {
                    link.classList.remove('active');
                });
                document.querySelectorAll('.content').forEach(function(content) {
                    content.classList.remove('active');
                });
                tablink.classList.add('active');
                document.getElementById(tablink.getAttribute('data-tab')).classList.add('active');
            });
        });
    </script>
</body>
</html>
