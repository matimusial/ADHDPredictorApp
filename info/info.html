<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ADHDPredictorApp</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        p {
            margin: 10px 0;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        nav {
            margin-bottom: 20px;
        }
        nav a {
            margin-right: 15px;
            color: #3498db;
        }
        nav a.active {
            font-weight: bold;
            color: #2c3e50;
        }
        .content {
            display: none;
        }
        .content.active {
            display: block;
        }
        .logo {
            width: 50px;
            height: 50px;
        }
        #gameArea {
            position: relative;
            width: 600px;
            height: 400px;
            margin: 0 auto;
            border: 2px solid #000;
            background-color: #f0f0f0;
        }
        #target {
            width: 30px;
            height: 30px;
            background-color: red;
            border-radius: 50%;
            position: absolute;
            cursor: pointer;
        }
        canvas {
            display: block;
            margin: 0 auto;
            background-color: #000;
            border: 2px solid #fff;
        }
        #gameArea {
            position: relative;
            width: 600px;
            height: 400px;
            margin: 0 auto;
            border: 2px solid #000;
            background-color: #f0f0f0;
        }

        #target {
            width: 30px;
            height: 30px;
            position: absolute;
            cursor: pointer;
        }

    </style>
</head>
<body>
    <img src="logo.png" alt="Logo" class="logo">
    <h1>ADHDPredictorApp</h1>
    <nav>
        <a href="#" class="tablink active" data-tab="overview">Overview</a>
        <a href="#" class="tablink" data-tab="admin">Admin Instructions</a>
        <a href="#" class="tablink" data-tab="specification">Specification</a>
        <a href="#" class="tablink" data-tab="click-the-red-dot">Click the Brain</a>
        <a href="#" class="tablink" data-tab="pong">Brain pong</a>
    </nav>

    <div id="overview" class="content active">
        <h2>Overview</h2>
        <p>This project aims to predict ADHD (Attention Deficit Hyperactivity Disorder) in children using Convolutional Neural Networks (CNN). It utilizes two main datasets: EEG brain wave data and MRI brain images. The project consists of two main components:</p>
        <ol>
            <li><strong>EEG Data Analysis</strong>: Using EEG data to predict the presence of ADHD in children with deep learning models.</li>
            <li><strong>MRI Data Augmentation and Analysis</strong>: Generating additional MRI brain images using Generative Adversarial Networks (GAN) and using CNN to predict ADHD from original images.</li>
        </ol>
        <h2>Datasets</h2>
        <h3>EEG Data</h3>
        <p>The EEG dataset is a collection of brain waves from children, both with and without ADHD. This data is crucial for training our model to identify patterns associated with ADHD.</p>
        <p><strong>Source</strong>: <a href="https://ieee-dataport.org/open-access/eeg-data-adhd-control-children">EEG Data for ADHD and Control Children</a></p>
        <h3>MRI Data</h3>
        <p>The MRI dataset provides brain images, which are used along with generated images to enhance the model's training and prediction capabilities.</p>
        <p><strong>Source</strong>: <a href="https://openneuro.org/datasets/ds002424/versions/1.2.0">OpenNeuro Dataset ds002424</a></p>
        <h2>Methodology</h2>
        <ol>
            <li><strong>EEG Data Processing and Model Training</strong>: EEG data is processed into a format suitable for CNN analysis. Then, a deep learning model is trained to identify ADHD features from EEG patterns.</li>
            <li><strong>MRI Image Generation and Processing</strong>: GANs are used to generate additional MRI images to increase the existing dataset. These images are then processed and used to train another CNN model to predict ADHD.</li>
        </ol>
        <h2>Objectives</h2>
        <ul>
            <li>Provide an accurate and reliable method for predicting ADHD using non-invasive EEG and MRI data.</li>
            <li>Increase the availability of high-quality MRI brain images through generative techniques, supporting the development of robust predictive models.</li>
        </ul>
        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="admin" class="content">
        <h2>Admin Instructions</h2>
        <p>To access the admin view, press the "Admin View" button on the left side of the program window (the one that appears when you start the program).</p>
        <ul>
            <li><strong>"GAN for MRI"</strong> - (Button) Window for training the GAN model to generate MRI images</li>
            <li><strong>"CNN for MRI"</strong> - (Button) Window for training the CNN model for MRI images</li>
            <li><strong>"CNN for EEG"</strong> - (Button) Window for training the CNN model for EEG waves</li>
            <li><strong>"Exit"</strong> - (Button) Closes the application</li>
            <li><strong>"Database Admin"</strong> - (Button) Connects to the database and displays its contents with the option to delete models (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"USER VIEW"</strong> - (Button) Returns to the main window</li>
        </ul>

        <h3>CNN for EEG</h3>
        <ul>
            <li><strong>"Choose folder with data"</strong> - (button) text type</li>
            <p>The folder with training data must have the following structure:</p>
            <pre>(chosen folder)
    |
    | ADHD
    |    |
    |    [files of the ADHD group .mat/.csv/.edf]
    |
    | CONTROL
    |    |
    |    [files of the control group .mat/.csv/.edf]</pre>
            <li><strong>"Epochs"</strong> - numeric type</li>
            <li><strong>"Batch size"</strong> - numeric type</li>
            <li><strong>"Learning rate"</strong> - floating-point type</li>
            <li><strong>"Description"</strong> - (text type) Description for the model saved in the database</li>
            <li><strong>"Start"</strong> - (button) Starts the model training process</li>
            <li><strong>"Stop"</strong> - (button) Stops the model training process at the last epoch</li>
            <li><strong>"Save model to db"</strong> - (button) When the model is ready, saves it to the database (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"Delete model"</strong> - (button) When the model is ready, deletes it without saving to the database</li>
        </ul>

        <h3>CNN for MRI</h3>
        <ul>
            <li><strong>"Epochs"</strong> - numeric type</li>
            <li><strong>"Batch size"</strong> - numeric type</li>
            <li><strong>"Learning rate"</strong> - floating-point type</li>
            <li><strong>"Description"</strong> - (text type) Description for the model saved in the database</li>
            <li><strong>"Start"</strong> - (button) Starts the model training process</li>
            <li><strong>"Stop"</strong> - (button) Stops the model training process at the last epoch</li>
            <li><strong>"Save model to db"</strong> - (button) When the model is ready, saves it to the database (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"Delete model"</strong> - (button) When the model is ready, deletes it without saving to the database</li>
        </ul>

        <h3>GAN for MRI</h3>
        <ul>
            <li><strong>"Epochs"</strong> - numeric type</li>
            <li><strong>"Batch size"</strong> - numeric type</li>
            <li><strong>"Learning rate"</strong> - floating-point type</li>
            <li><strong>"Control/ADHD"</strong> - radio button to select the type of training data</li>
            <li><strong>"Print plot int."</strong> - numeric type</li>
            <li><strong>"Disp interval"</strong> - numeric type</li>
            <li><strong>"Description"</strong> - (text type) Description for the model saved in the database</li>
            <li><strong>"Start"</strong> - (button) Starts the model training process</li>
            <li><strong>"Stop"</strong> - (button) Stops the model training process at the last epoch</li>
            <li><strong>"Save model to db"</strong> - (button) When the model is ready, saves it to the database (NOTE: requires VPN connection to the ZUT network)</li>
            <li><strong>"Delete model"</strong> - (button) When the model is ready, deletes it without saving to the database</li>
        </ul>

        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="specification" class="content">
        <h2>Specification</h2>
        <h3>Data Analysis for Training CNN with EEG Data</h3>
        <ol>
            <li><strong>Data Loading and Filtering:</strong> EEG data is processed with a Butterworth bandpass filter with a lower frequency of 4 Hz and an upper frequency of 30 Hz.</li>
            <li><strong>Data Clipping:</strong> After filtering, the data is clipped to the 99.8th percentile, removing the extreme 0.2% of data.</li>
            <li><strong>Data Normalization:</strong> Data is normalized to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is transformed into images of fixed size (frame size), labeled, shuffled, and fed into the neural network in the shape (number of images, number of channels, frame size, 1).</li>
        </ol>
        <h3>CNN Architecture for EEG Training</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(number of channels, frame size, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 16.</li>
                    <li>Kernel size: (10, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Feature extraction from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (8, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (4, 1).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>BatchNormalization: Data optimization.</li>
                    <li>Description: Extraction of even more complex features from EEG data.</li>
                </ul>
            </li>
            <li><strong>Average Pooling:</strong>
                <ul>
                    <li>Layer: AveragePooling2D.</li>
                    <li>Pool size: (2, 1).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 64.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Regularization: kernel_regularizer=l2(0.005).</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Data Analysis for Training CNN with MRI Data</h3>
        <ol>
            <li><strong>Data Loading:</strong> Data with image size 128x120.</li>
            <li><strong>Data Clipping:</strong> Clipping by 4 pixels top-bottom, checking if the image is square.</li>
            <li><strong>Data Normalization:</strong> Normalizing to the range [-1;1].</li>
            <li><strong>Data Transformation:</strong> Data is labeled and fed into training as (number of images, 120, 120, 1).</li>
        </ol>
        <h3>Training CNN for MRI Data</h3>
        <p><strong>Training Method:</strong></p>
        <ul>
            <li>Optimization algorithm: Adam.</li>
            <li>Loss function: binary_crossentropy.</li>
            <li>Callback ReduceLROnPlateau monitors validation loss (val_loss) and reduces the learning rate by half if the loss does not improve for 2 epochs (minimum rate: 0.0001).</li>
        </ul>
        <p><strong>Input Shape:</strong></p>
        <ul>
            <li>(120, 120, 1).</li>
        </ul>
        <h3>CNN Model</h3>
        <ol>
            <li><strong>First Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 32.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of basic features from input data.</li>
                </ul>
            </li>
            <li><strong>First Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Second Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 64.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Second Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Third Convolutional Layer:</strong>
                <ul>
                    <li>Layer: Conv2D.</li>
                    <li>Filters: 128.</li>
                    <li>Kernel size: (3, 3).</li>
                    <li>Activation: 'relu'.</li>
                    <li>Padding: 'same'.</li>
                    <li>Description: Extraction of even more complex features from data.</li>
                </ul>
            </li>
            <li><strong>Third Max Pooling:</strong>
                <ul>
                    <li>Layer: MaxPooling2D.</li>
                    <li>Pool size: (2, 2).</li>
                    <li>Description: Data dimension reduction, feature aggregation.</li>
                </ul>
            </li>
            <li><strong>Flattening:</strong>
                <ul>
                    <li>Layer: Flatten.</li>
                    <li>Description: Transforming 2D data to 1D to enter the dense layer.</li>
                </ul>
            </li>
            <li><strong>First Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 128.</li>
                    <li>Activation: 'relu'.</li>
                    <li>Description: Full connection learning complex relationships in the data.</li>
                </ul>
            </li>
            <li><strong>Dropout:</strong>
                <ul>
                    <li>Layer: Dropout.</li>
                    <li>Parameters: rate=0.5.</li>
                    <li>Description: Regularizing the model by dropping 50% of neurons during training to prevent overfitting.</li>
                </ul>
            </li>
            <li><strong>Output Dense Layer:</strong>
                <ul>
                    <li>Layer: Dense.</li>
                    <li>Units: 1.</li>
                    <li>Activation: 'sigmoid'.</li>
                    <li>Description: Final layer that produces binary output (classification probability).</li>
                </ul>
            </li>
        </ol>
        <h3>Prediction for CNN Models for EEG and MRI</h3>
        <p><strong>Data Processing:</strong></p>
        <ul>
            <li>Data processed the same way as before training.</li>
            <li>The model returns a binary probability for each frame.</li>
            <li>The mean of the frames is calculated:
                <ul>
                    <li>If the mean exceeds the threshold of 0.5, the result is ADHD, and the mean * 100% is displayed.</li>
                    <li>If the result is healthy, (1 - mean) * 100% is displayed.</li>
                </ul>
            </li>
        </ul>
        <h3>Building and Training GAN Model</h3>
        <ol>
            <li><strong>Building the Generative Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 1024 units, LeakyReLU with slope 0.2, BatchNormalization.</li>
                            <li>Dense: 120 * 120 * 1, activation 'tanh', Reshape to shape (120,120,1).</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Building the Discriminator Model:</strong>
                <ul>
                    <li>Model: Sequential.</li>
                    <li>Layers:
                        <ul>
                            <li>Input: Input shape (120, 120, 1).</li>
                            <li>Flatten.</li>
                            <li>Dense: 512 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 256 units, LeakyReLU with slope 0.2, Dropout 0.3.</li>
                            <li>Dense: 1, activation 'sigmoid'.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Training the GAN Model:</strong>
                <ul>
                    <li>Gradient Tape: Using two tf.GradientTape objects to record operations for calculating gradients for the generator and discriminator.</li>
                    <li>Generating images: Generating fake images using the generator.</li>
                    <li>Passing through the discriminator:
                        <ul>
                            <li>Passing real images through the discriminator.</li>
                            <li>Passing generated images through the discriminator.</li>
                        </ul>
                    </li>
                    <li>Calculating losses:
                        <ul>
                            <li>Loss for the generator: g_loss calculated as the error of classifying fake images as real.</li>
                        </ul>
                    </li>
                    <li>Calculating gradients:
                        <ul>
                            <li>Gradients for the discriminator.</li>
                            <li>Gradients for the generator.</li>
                        </ul>
                    </li>
                    <li>Updating weights:
                        <ul>
                            <li>Applying gradients to optimizers to update weights of the discriminator and generator.</li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ol>
        <footer>
            <p>&copy; Mateusz Musiał, Jacek Lal, Radosław Nelza, Artur Panasiuk</p>
        </footer>
    </div>

    <div id="click-the-red-dot" class="content">
        <h2>Click the Brain</h2>
        <div id="gameArea">
            <img id="target" src="pilka.png" alt="Target">
        </div>
        <p>Result: <span id="score">0</span></p>
    </div>

    <div id="pong" class="content">
        <h2>Brain pong</h2>
        <canvas id="pongCanvas"></canvas>
    </div>

    <script>
        document.querySelectorAll('.tablink').forEach(function(tablink) {
            tablink.addEventListener('click', function(e) {
                e.preventDefault();
                document.querySelectorAll('.tablink').forEach(function(link) {
                    link.classList.remove('active');
                });
                document.querySelectorAll('.content').forEach(function(content) {
                    content.classList.remove('active');
                });
                tablink.classList.add('active');
                document.getElementById(tablink.getAttribute('data-tab')).classList.add('active');
            });
        });

        // Click the Red Dot Game Script
        document.addEventListener('DOMContentLoaded', (event) => {
            const gameArea = document.getElementById('gameArea');
            const target = document.getElementById('target');
            const scoreDisplay = document.getElementById('score');
            let score = 0;

            function moveTarget() {
                const gameAreaRect = gameArea.getBoundingClientRect();
                const maxX = gameAreaRect.width - target.clientWidth;
                const maxY = gameAreaRect.height - target.clientHeight;

                const randomX = Math.floor(Math.random() * maxX);
                const randomY = Math.floor(Math.random() * maxY);

                target.style.left = `${randomX}px`;
                target.style.top = `${randomY}px`;
            }

            target.addEventListener('click', () => {
                score++;
                scoreDisplay.textContent = score;
                moveTarget();
            });

            moveTarget();
        });


        // Pong Game Script
        const canvas = document.getElementById('pongCanvas');
        const ctx = canvas.getContext('2d');

        canvas.width = 800;
        canvas.height = 400;

        const paddleWidth = 10;
        const paddleHeight = 100;
        const ballRadius = 10;

        const playerPaddle = {
            x: 10,
            y: canvas.height / 2 - paddleHeight / 2,
            width: paddleWidth,
            height: paddleHeight,
            dy: 0,
            speed: 6
        };

        const computerPaddle = {
            x: canvas.width - 10 - paddleWidth,
            y: canvas.height / 2 - paddleHeight / 2,
            width: paddleWidth,
            height: paddleHeight,
            dy: 4
        };

        const ball = {
            x: canvas.width / 2,
            y: canvas.height / 2,
            radius: ballRadius,
            dx: 4,
            dy: 4
        };

        const ballImg = new Image();
        ballImg.src = 'pilka.png';

        function drawRect(x, y, width, height) {
            ctx.fillStyle = '#fff';
            ctx.fillRect(x, y, width, height);
        }

        function drawImage(img, x, y, width, height) {
            ctx.drawImage(img, x, y, width, height);
        }

        function update() {
            // Move player paddle
            playerPaddle.y += playerPaddle.dy;

            // Prevent player paddle from going out of bounds
            if (playerPaddle.y < 0) {
                playerPaddle.y = 0;
            }
            if (playerPaddle.y + playerPaddle.height > canvas.height) {
                playerPaddle.y = canvas.height - playerPaddle.height;
            }

            // Move computer paddle
            if (ball.y < computerPaddle.y + computerPaddle.height / 2) {
                computerPaddle.y -= computerPaddle.dy;
            } else {
                computerPaddle.y += computerPaddle.dy;
            }

            // Prevent computer paddle from going out of bounds
            if (computerPaddle.y < 0) {
                computerPaddle.y = 0;
            }
            if (computerPaddle.y + computerPaddle.height > canvas.height) {
                computerPaddle.y = canvas.height - computerPaddle.height;
            }

            // Move ball
            ball.x += ball.dx;
            ball.y += ball.dy;

            // Ball collision with top and bottom walls
            if (ball.y - ball.radius < 0 || ball.y + ball.radius > canvas.height) {
                ball.dy *= -1;
            }

            // Ball collision with paddles
            if (
                (ball.x - ball.radius < playerPaddle.x + playerPaddle.width &&
                ball.y > playerPaddle.y &&
                ball.y < playerPaddle.y + playerPaddle.height) ||
                (ball.x + ball.radius > computerPaddle.x &&
                ball.y > computerPaddle.y &&
                ball.y < computerPaddle.y + computerPaddle.height)
            ) {
                ball.dx *= -1;
            }

            // Reset ball if it goes out of bounds
            if (ball.x - ball.radius < 0 || ball.x + ball.radius > canvas.width) {
                ball.x = canvas.width / 2;
                ball.y = canvas.height / 2;
                ball.dx *= -1;
            }
        }

        function draw() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            drawRect(playerPaddle.x, playerPaddle.y, playerPaddle.width, playerPaddle.height);
            drawRect(computerPaddle.x, computerPaddle.y, computerPaddle.width, computerPaddle.height);
            drawImage(ballImg, ball.x - ball.radius, ball.y - ball.radius, ball.radius * 2, ball.radius * 2);
        }

        function loop() {
            update();
            draw();
            requestAnimationFrame(loop);
        }

        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowUp') {
                playerPaddle.dy = -playerPaddle.speed;
            } else if (e.key === 'ArrowDown') {
                playerPaddle.dy = playerPaddle.speed;
            }
        });

        document.addEventListener('keyup', (e) => {
            if (e.key === 'ArrowUp' || e.key === 'ArrowDown') {
                playerPaddle.dy = 0;
            }
        });

        loop();

    </script>
</body>
</html>
